
<p>
The <b>RASE 2026 Challenge</b> explores the next frontier in speech enhancement by leveraging <b>mmWave radar</b> as a sensing modality. Traditional microphone-based systems often fail in noisy, obstructed, or privacy-sensitive environments. Radar provides a contactless, non-intrusive alternative capable of capturing rich motion and articulation cues through physical barriers such as glass.
</p>

<p>
Participants are tasked with developing models that reconstruct clean and intelligible speech signals from radar echoes recorded across varying environments, user orientations, and glass conditions. This is a highly interdisciplinary challenge at the intersection of <b>signal processing, machine learning, and wireless sensing</b>.
</p>

<p>
We provide a curated dataset of paired radar–audio signals for training. Models will be evaluated on held-out test data using a combination of objective speech quality and intelligibility metrics, including <b>PESQ, ESTOI, DNSMOS, MFCC similarity</b>, and a final weighted score. Leaderboards will track performance across phases, encouraging both innovation and reproducibility.
</p>

<p>
The ultimate goal of RASE 2026 is to benchmark state-of-the-art methods, foster collaboration between the radar and speech research communities, and pave the way for <b>real-world applications in healthcare, security, and human–machine interaction</b>.
</p>
