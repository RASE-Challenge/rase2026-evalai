# ============================
# RASE 2026 Challenge (EvalAI)
# ============================

title: "RASE 2026: Radar Acoustic Speech Enhancement"
short_description: "Recover clean speech from mmWave radar through glass barriers."
description: templates/description.html
evaluation_details: templates/evaluation_details.html
terms_and_conditions: templates/terms_and_conditions.html
submission_guidelines: templates/submission_guidelines.html
leaderboard_description: "Primary leaderboard uses PESQ, ESTOI, DNSMOS, MFCC Cosine Similarity, and a weighted Final score."
image: logo.jpg     # optional; place a logo.jpg in the repo root or remove this line

# ---- IMPORTANT ----
# We evaluate on your private machine via remote worker.
remote_evaluation: true

# Challenge visibility timeframe (UTC)
start_date: "2025-09-07 00:00:00"
end_date:   "2026-02-10 23:59:59"

published: true
tags:
  - speech-enhancement
  - mmwave
  - radar
  - audio

# ---------------------
# Leaderboard definition
# ---------------------
leaderboard:
  - id: rase_board
    schema:
      labels: ["PESQ", "ESTOI", "DNSMOS", "MFCC_Cosine", "Final"]
      default_order_by: "Final"
      metadata:
        PESQ:
          sort_ascending: false   # higher is better
          description: "Perceptual Evaluation of Speech Quality."
        ESTOI:
          sort_ascending: false   # higher is better
          description: "Extended Short-Time Objective Intelligibility."
        DNSMOS:
          sort_ascending: false   # higher is better
          description: "Deep Noise Suppression MOS."
        MFCC_Cosine:
          sort_ascending: false   # higher is better
          description: "Cosine similarity in MFCC domain."
        Final:
          sort_ascending: false   # higher is better (our composite)

# ---------------------
# Dataset split(s)
# ---------------------
dataset_splits:
  - id: 1
    name: "Test"
    codename: "test"

# ---------------------
# Phases (single-phase)
# ---------------------
challenge_phases:
  - id: 1
    name: "Main Phase"
    description: templates/challenge_phase_main.html
    leaderboard_public: true
    is_public: true
    challenge: 1
    is_active: true

    # Docker + remote eval: submissions are docker images pushed via evalai CLI
    is_docker_based: true

    # submission concurrency and caps
    max_concurrent_submissions_allowed: 2
    max_submissions_per_day: 3
    max_submissions_per_month: 30
    max_submissions: 50

    allowed_email_ids: []       # keep empty (allow all), or restrict by domain here
    disable_logs: false
    is_submission_public: false

    start_date: "2025-09-07 00:00:00"
    end_date:   "2026-02-10 23:59:59"

    # Annotation file (can be empty list) — required by EvalAI
    test_annotation_file: annotations/test.json

    # This "codename" must match what your evaluation script expects
    codename: "main_phase"

    # Optional fields shown for each submission
    default_submission_meta_attributes:
      - name: method_name
        is_visible: true
      - name: method_description
        is_visible: true
      - name: project_url
        is_visible: true
      - name: publication_url
        is_visible: true

    # If you want extra fields users must fill at submission time:
    submission_meta_attributes: []

    # Whether participants can mark exactly one “selected” submission
    is_restricted_to_select_one_submission: false
    is_partial_submission_evaluation_enabled: false

    # file types for non-docker phases (kept for completeness; not used here)
    allowed_submission_file_types: ".json, .zip, .txt, .tsv, .gz, .csv, .h5, .npy, .npz"

# -------------------------
# Phase ↔ Split ↔ Leaderboard
# -------------------------
challenge_phase_splits:
  - challenge_phase_id: 1
    leaderboard_id: rase_board
    dataset_split_id: 1
    visibility: 3                     # show to all
    leaderboard_decimal_precision: 3
    is_leaderboard_order_descending: true
    show_execution_time: true
    show_leaderboard_by_latest_submission: true
