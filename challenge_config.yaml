# ============================
# RASE 2026 Challenge (EvalAI)
# ============================

title: "RASE 2026: Radar Acoustic Speech Enhancement"
short_description: "Recover clean speech from mmWave radar through glass barriers."
description: templates/description.html
evaluation_details: templates/evaluation_details.html
terms_and_conditions: templates/terms_and_conditions.html
submission_guidelines: templates/submission_guidelines.html
leaderboard_description: "Primary leaderboard uses PESQ, ESTOI, DNSMOS, MFCC Cosine Similarity, and a weighted Final score."
image: logo.jpg     # optional; place a logo.jpg in the repo root or remove this line

# üëá repo root
evaluation_script: evaluation_script.zip

# ---- IMPORTANT ----
# We evaluate on your private machine via remote worker.
remote_evaluation: true

# Challenge visibility timeframe (UTC)
start_date: "2025-09-07 00:00:00"
end_date:   "2026-02-10 23:59:59"

published: true
tags:
  - speech-enhancement
  - mmwave
  - radar
  - audio

# ---------------------
# Leaderboard definition
# ---------------------
leaderboard:
  - id: 1
    schema:
      {
        "labels": ["PESQ", "ESTOI", "DNSMOS", "MFCC-CS", "Total"],
        "default_order_by": "Total",
        "metadata": {
          "PESQ":     { "sort_ascending": false, "description": "Perceptual Evaluation of Speech Quality (weighted across difficulties)." },
          "ESTOI":    { "sort_ascending": false, "description": "Extended STOI (weighted)." },
          "DNSMOS":   { "sort_ascending": false, "description": "DNSMOS (weighted)." },
          "MFCC-CS":  { "sort_ascending": false, "description": "MFCC cosine similarity (weighted)." },
          "Total":    { "sort_ascending": false, "description": "Aggregate of the four weighted metrics." }
        }
      }


# ---------------------
# Dataset split(s)
# ---------------------
dataset_splits:
  - id: 1
    name: "Test"
    codename: "test"

# ---------------------
# Phases (single-phase)
# ---------------------
challenge_phases:
  - id: 1
    name: "Main Phase"
    description: templates/challenge_phase_1_description.html
    leaderboard_public: true
    is_public: true
    challenge: 1
    is_active: true

    # Docker + remote eval: submissions are docker images pushed via evalai CLI
    is_docker_based: true

    # submission concurrency and caps
    max_concurrent_submissions_allowed: 2
    max_submissions_per_day: 3
    max_submissions_per_month: 30
    max_submissions: 50

    allowed_email_ids: []       # keep empty (allow all), or restrict by domain here
    disable_logs: false
    is_submission_public: false

    start_date: "2025-09-07 00:00:00"
    end_date:   "2026-02-10 23:59:59"

    # Annotation file (can be empty list) ‚Äî required by EvalAI
    test_annotation_file: annotations/test_annotations_testsplit.json

    # This "codename" must match what your evaluation script expects
    codename: "main_phase"

    # Optional fields shown for each submission
    default_submission_meta_attributes:
      - name: method_name
        is_visible: true
      - name: method_description
        is_visible: true
      - name: project_url
        is_visible: true
      - name: publication_url
        is_visible: true

    # If you want extra fields users must fill at submission time:
    submission_meta_attributes: []

    # Whether participants can mark exactly one ‚Äúselected‚Äù submission
    is_restricted_to_select_one_submission: false
    is_partial_submission_evaluation_enabled: false

    # file types for non-docker phases (kept for completeness; not used here)
    allowed_submission_file_types: ".json, .zip, .txt, .tsv, .gz, .csv, .h5, .npy, .npz"

# -------------------------
# Phase ‚Üî Split ‚Üî Leaderboard
# -------------------------
challenge_phase_splits:
  - challenge_phase_id: 1
    leaderboard_id: 1
    dataset_split_id: 1
    visibility: 3                     # show to all
    leaderboard_decimal_precision: 3
    is_leaderboard_order_descending: true
    show_execution_time: true
    show_leaderboard_by_latest_submission: true


